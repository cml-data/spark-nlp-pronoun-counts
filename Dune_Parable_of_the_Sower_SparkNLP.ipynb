{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ46j-PD-eXS"
      },
      "source": [
        "Let's set up SparkNLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz8walkjXq0I",
        "outputId": "98cbe176-c716-4f0d-bf38-a63199df7b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-23 16:21:08--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 3.86.22.73\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|3.86.22.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2024-07-23 16:21:08--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-23 16:21:08 (58.3 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 5.4.1\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.4.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8trkawwfX8bx"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSv2iBclzWMr",
        "outputId": "40b039e9-a5e8-46f7-abf2-b81d2f396130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "pipeline = PretrainedPipeline(\"explain_document_ml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzvSSJOQ-kKm"
      },
      "source": [
        "We can use some recent headlines."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hls = [\n",
        "\t\t\"She ran.\",\n",
        "\t\t\"He ran.\",\n",
        "\t\t\"I saw her.\",\n",
        "\t\t\"I saw him.\",\n",
        "\t\t\"I know her name.\",\n",
        "\t\t\"I know his name.\",\n",
        "\t\t\"That is hers.\",\n",
        "\t\t\"That is his.\"\n",
        "\t]"
      ],
      "metadata": {
        "id": "VC-21qMEpLWM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaexWg9g-oJJ"
      },
      "source": [
        "Let's use SparkNLP to analyze these headlines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FkD7QdVMZPjT"
      },
      "outputs": [],
      "source": [
        "# Use dataframes, or...\n",
        "# data = spark.createDataFrame(hls).toDF(\"text\")\n",
        "# dfs = pipeline.transform(data)\n",
        "# ... use list comprehension\n",
        "dfs = [pipeline.annotate(hl) for hl in hls] # I don't know how to use dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xWvlqNUSYxjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a9e6b8-c4d3-4adf-d582-2cd63a97df62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'document': ['She ran.'],\n",
              "  'spell': ['She', 'ran', '.'],\n",
              "  'pos': ['PRP', 'VBD', '.'],\n",
              "  'lemmas': ['She', 'run', '.'],\n",
              "  'token': ['She', 'ran', '.'],\n",
              "  'stems': ['she', 'ran', '.'],\n",
              "  'sentence': ['She ran.']},\n",
              " {'document': ['He ran.'],\n",
              "  'spell': ['He', 'ran', '.'],\n",
              "  'pos': ['PRP', 'VBD', '.'],\n",
              "  'lemmas': ['He', 'run', '.'],\n",
              "  'token': ['He', 'ran', '.'],\n",
              "  'stems': ['he', 'ran', '.'],\n",
              "  'sentence': ['He ran.']},\n",
              " {'document': ['I saw her.'],\n",
              "  'spell': ['I', 'saw', 'her', '.'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP', '.'],\n",
              "  'lemmas': ['I', 'see', 'she', '.'],\n",
              "  'token': ['I', 'saw', 'her', '.'],\n",
              "  'stems': ['i', 'saw', 'her', '.'],\n",
              "  'sentence': ['I saw her.']},\n",
              " {'document': ['I saw him.'],\n",
              "  'spell': ['I', 'saw', 'him', '.'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP', '.'],\n",
              "  'lemmas': ['I', 'see', 'he', '.'],\n",
              "  'token': ['I', 'saw', 'him', '.'],\n",
              "  'stems': ['i', 'saw', 'him', '.'],\n",
              "  'sentence': ['I saw him.']},\n",
              " {'document': ['I know her name.'],\n",
              "  'spell': ['I', 'know', 'her', 'name', '.'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN', '.'],\n",
              "  'lemmas': ['I', 'know', 'she', 'name', '.'],\n",
              "  'token': ['I', 'know', 'her', 'name', '.'],\n",
              "  'stems': ['i', 'know', 'her', 'name', '.'],\n",
              "  'sentence': ['I know her name.']},\n",
              " {'document': ['I know his name.'],\n",
              "  'spell': ['I', 'know', 'his', 'name', '.'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN', '.'],\n",
              "  'lemmas': ['I', 'know', 'he', 'name', '.'],\n",
              "  'token': ['I', 'know', 'his', 'name', '.'],\n",
              "  'stems': ['i', 'know', 'hi', 'name', '.'],\n",
              "  'sentence': ['I know his name.']},\n",
              " {'document': ['That is hers.'],\n",
              "  'spell': ['That', 'is', 'hers', '.'],\n",
              "  'pos': ['DT', 'VBZ', 'NNS', '.'],\n",
              "  'lemmas': ['That', 'be', 'hers', '.'],\n",
              "  'token': ['That', 'is', 'hers', '.'],\n",
              "  'stems': ['that', 'i', 'her', '.'],\n",
              "  'sentence': ['That is hers.']},\n",
              " {'document': ['That is his.'],\n",
              "  'spell': ['That', 'is', 'his', '.'],\n",
              "  'pos': ['DT', 'VBZ', 'PRP$', '.'],\n",
              "  'lemmas': ['That', 'be', 'he', '.'],\n",
              "  'token': ['That', 'is', 'his', '.'],\n",
              "  'stems': ['that', 'i', 'hi', '.'],\n",
              "  'sentence': ['That is his.']}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# its big\n",
        "dfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbYI4VqB1JCh"
      },
      "source": [
        "Let's say we want to fuse part-of-speech tags to words, to make word differentiation easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ObEtMFe2aFTr"
      },
      "outputs": [],
      "source": [
        "# Extract words and parts-of-speech\n",
        "tok_tag = [(df['token'],df['pos']) for df in dfs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DjmzGUa9au-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b2045c-aa25-408b-b2e0-f46476c6b55e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['She', 'ran', '.'], ['PRP', 'VBD', '.']),\n",
              " (['He', 'ran', '.'], ['PRP', 'VBD', '.']),\n",
              " (['I', 'saw', 'her', '.'], ['PRP', 'VBD', 'PRP', '.']),\n",
              " (['I', 'saw', 'him', '.'], ['PRP', 'VBD', 'PRP', '.']),\n",
              " (['I', 'know', 'her', 'name', '.'], ['PRP', 'VBP', 'PRP$', 'NN', '.']),\n",
              " (['I', 'know', 'his', 'name', '.'], ['PRP', 'VBP', 'PRP$', 'NN', '.']),\n",
              " (['That', 'is', 'hers', '.'], ['DT', 'VBZ', 'NNS', '.']),\n",
              " (['That', 'is', 'his', '.'], ['DT', 'VBZ', 'PRP$', '.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Still big\n",
        "tok_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_quMwObV253r"
      },
      "outputs": [],
      "source": [
        "# fuse pos to word\n",
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OhtChnE3s0R",
        "outputId": "3fc9a92a-294e-4633-8a4a-ebbc94d5410c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('She', 'PRP'), ('ran', 'VBD'), ('.', '.')],\n",
              " [('He', 'PRP'), ('ran', 'VBD'), ('.', '.')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('her', 'PRP'), ('.', '.')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('him', 'PRP'), ('.', '.')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('her', 'PRP$'), ('name', 'NN'), ('.', '.')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('his', 'PRP$'), ('name', 'NN'), ('.', '.')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('hers', 'NNS'), ('.', '.')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('his', 'PRP$'), ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# not too big\n",
        "zips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "plqXGLJ04aVC"
      },
      "outputs": [],
      "source": [
        "tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs45yaMK4nn-",
        "outputId": "219c4a37-cffd-4751-fd4a-9b282a6d7748"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ShePRP ranVBD ..',\n",
              " 'HePRP ranVBD ..',\n",
              " 'IPRP sawVBD herPRP ..',\n",
              " 'IPRP sawVBD himPRP ..',\n",
              " 'IPRP knowVBP herPRP$ nameNN ..',\n",
              " 'IPRP knowVBP hisPRP$ nameNN ..',\n",
              " 'ThatDT isVBZ hersNNS ..',\n",
              " 'ThatDT isVBZ hisPRP$ ..']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tagged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVnTs4mW5Acm"
      },
      "source": [
        "What about ebooks?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l-dsu3Pkd9YT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu7LjNBx91G2",
        "outputId": "feacd2c5-7a08-410e-dc9e-15241beba0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He Count:  2655\n",
            "She Count:  1490\n",
            "Him Count:  950\n",
            "Her Count:  190\n"
          ]
        }
      ],
      "source": [
        "he_count = 0\n",
        "him_count = 0\n",
        "she_count = 0\n",
        "her_count = 0\n",
        "with open('dune.txt') as dune:\n",
        "    i = 1\n",
        "    masculine_object = [('Him', 'PRP'), ('him', 'PRP')]\n",
        "    masculine_subject = [('He', 'PRP'), ('he', 'PRP')]\n",
        "    feminine_object = [('Her', 'PRP'), ('her', 'PRP')]\n",
        "    feminine_subject = [('She', 'PRP'), ('she', 'PRP')]\n",
        "    feminine_possessive = [('Her', 'PRP$'), ('her', 'PRP$')]\n",
        "    masculine_possessive = [('His', 'PRP$'), ('his', 'PRP$')]\n",
        "    line = dune.readline()\n",
        "    while line:\n",
        "      annotated_line = pipeline.annotate(line)\n",
        "      merged_list = tuple(zip(annotated_line['token'], annotated_line['pos']))\n",
        "\n",
        "      #Count matches per line in each category\n",
        "      her_count = her_count + len(set(feminine_object).intersection(merged_list))\n",
        "      she_count = she_count + len(set(feminine_subject).intersection(merged_list))\n",
        "      he_count = he_count + len(set(masculine_subject).intersection(merged_list))\n",
        "      him_count = him_count + len(set(masculine_object).intersection(merged_list))\n",
        "\n",
        "      i = i + 1\n",
        "      line = dune.readline()\n",
        "      #if i > 200:\n",
        "      #  break;\n",
        "\n",
        "print(\"He Count: \", he_count)\n",
        "print(\"She Count: \", she_count)\n",
        "print(\"Him Count: \",  him_count)\n",
        "print(\"Her Count: \",  her_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sk40mSd-ZF2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_pronouns(book):\n",
        "\the_count = 0\n",
        "\thim_count = 0\n",
        "\tshe_count = 0\n",
        "\ther_count = 0\n",
        "\ther_possessive_count = 0\n",
        "\this_possessive_count = 0\n",
        "\tmasculine_object = [('Him', 'PRP'), ('him', 'PRP')]\n",
        "\tmasculine_subject = [('He', 'PRP'), ('he', 'PRP')]\n",
        "\tfeminine_object = [('Her', 'PRP'), ('her', 'PRP')]\n",
        "\tfeminine_subject = [('She', 'PRP'), ('she', 'PRP')]\n",
        "\tfeminine_possessive = [('Her', 'PRP$'), ('her', 'PRP$')]\n",
        "\tmasculine_possessive = [('His', 'PRP$'), ('his', 'PRP$')]\n",
        "\twith open(book) as booktext:\n",
        "\t\ti = 1\n",
        "\t\tline = booktext.readline()\n",
        "\t\twhile line:\n",
        "\t\t\tannotated_line = pipeline.annotate(line)\n",
        "\t\t\tmerged_list = tuple(zip(annotated_line['token'], annotated_line['pos']))\n",
        "\n",
        "\t\t\t#Count matches per line in each category\n",
        "\t\t\ther_count = her_count + len(set(feminine_object).intersection(merged_list))\n",
        "\t\t\tshe_count = she_count + len(set(feminine_subject).intersection(merged_list))\n",
        "\t\t\the_count = he_count + len(set(masculine_subject).intersection(merged_list))\n",
        "\t\t\thim_count = him_count + len(set(masculine_object).intersection(merged_list))\n",
        "\t\t\ther_possessive_count = her_possessive_count + len(set(feminine_possessive).intersection(merged_list))\n",
        "\t\t\this_possessive_count = his_possessive_count + len(set(masculine_possessive).intersection(merged_list))\n",
        "\n",
        "\t\t\ti = i + 1\n",
        "\t\t\tline = booktext.readline()\n",
        "    \t#if i > 200:\n",
        "    \t#  break;\n",
        "\n",
        "\tprint(\"He Count: \", he_count)\n",
        "\tprint(\"She Count: \", she_count)\n",
        "\tprint(\"Him Count: \",  him_count)\n",
        "\tprint(\"Her Count: \",  her_count)\n",
        "\tprint(\"Her possessive Count: \", her_possessive_count)\n",
        "\tprint(\"His possessive Count: \", his_possessive_count)"
      ],
      "metadata": {
        "id": "2j_Eyp2XVNlk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://raw.githubusercontent.com/cml-data/mktsv/main/dune.txt\" -o dune.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEtGa-zVdZee",
        "outputId": "5d48c24a-c36f-4d7a-e3bb-cc204c087444"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1079k  100 1079k    0     0  1905k      0 --:--:-- --:--:-- --:--:-- 1903k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://raw.githubusercontent.com/cml-data/mktsv/main/parable.txt\" -o parable.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pApP9XXsdaM3",
        "outputId": "27daaca1-42a7-4e53-922f-d730d1970941"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  538k  100  538k    0     0  1097k      0 --:--:-- --:--:-- --:--:-- 1097k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_pronouns('dune.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KfsdjBBeD3Q",
        "outputId": "a77ee442-8e78-4966-9acb-345285997202"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He Count:  2655\n",
            "She Count:  1490\n",
            "Him Count:  950\n",
            "Her Count:  190\n",
            "Her possessive Count:  963\n",
            "His possessive Count:  2250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_pronouns('parable.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT8mvUvRDTR-",
        "outputId": "86eed88f-6177-47cd-b8dc-2a3c1e30633a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He Count:  1023\n",
            "She Count:  615\n",
            "Him Count:  408\n",
            "Her Count:  137\n",
            "Her possessive Count:  452\n",
            "His possessive Count:  370\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}